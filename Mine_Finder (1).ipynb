{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51872ae0-899d-43f3-894b-fac3f1f27441",
   "metadata": {},
   "source": [
    "# Using Knn Classifier to differentiate Water Mines from Rocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012c727-a24c-46e6-bdeb-fe76f9293228",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "\n",
    "### The Sonar system\n",
    "The Sonar is a system that uses sound waves to detect objects under the water. (oceanservice.noaa.gov) It is mostly used to locate underwater hazards for navigation, search and map objects on the seafloor such as shipwrecks, and map the seafloor itself. (oceanservice.noaa.gov) What is interesting about these sound wave signals, which we will be using in our project as well, is the fact that the patterns of the signals bouncing off metal cylinders vs. similar shaped rocks are different. This property can be used to detect hidden mines in the mine field.\n",
    "\n",
    "\n",
    "\n",
    "### The Data Structure of the Presented Sonar Signals\n",
    "\n",
    "Gorman and Sejnowski reported a data set that contains sonar signals of mine and rock sample. A beam of sonar wave was sent to the target. The reflected signal was processed by the sonar system and recorded in a matrix. The spectrum was divided into 60 bands, and intensity of the signal at each frequency band was noted with a value between 0 to 1. \n",
    "\n",
    "Each of these sets of frequencies is tied to a label which is either “M” for metal cylinder or “R” for roughly cylindrical rock. \n",
    "\n",
    "### Introduction to Knn classifier model\n",
    "\n",
    "To do\n",
    "\n",
    "In this project, we will be training the system, which will determine whether the solar system that is being bounced off, is from a metal cylinder, or a roughly cylindrical rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a72f8e0d-8905-4125-beb8-092c14307da8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataTransformerRegistry.enable('default')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up the environment\n",
    "import random\n",
    "\n",
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_validate,\n",
    "    train_test_split,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "\n",
    "# Simplify working with large datasets in Altair\n",
    "alt.data_transformers.disable_max_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2568952-6ed5-4991-80ef-164ea2b3008c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Methods:\n",
    "\n",
    "In this project, we will train a mine detecting model through the following stages:\n",
    "\n",
    "  - Exploratory data analysis:\n",
    "  - Using SearchgridCV to select the best K value\n",
    "  - Model training\n",
    "  - Model performance analysis\n",
    "\n",
    "First, the dataset is loaded and cleaned. Then, we verify if the data is balanced. Next, data is then split to training and testing set in a 75-25 ratio. After verifying the balance of the sub data sets, we will conduct some exploratory visualization to arm our intuition for exploiting this data set. \n",
    "\n",
    "We will train a Knn model to distinguish the mine from rocks. To achieve that, we will perform grid search with 5-fold cross-validation to find the best value for k (number of neighbors). Using the optimum K value, we will train the Knn Classifier, and use our test data set to evaluate the performance of our model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ab7c5-cec5-43dc-b9cf-34c4657899b2",
   "metadata": {},
   "source": [
    "### Exploratory data analysis:\n",
    "#### Load Data\n",
    "\n",
    "The data set was stored at Kaggle in .csv format. \n",
    "\n",
    "To ensure this data is loadable regardless of users, GitHub is used to host this file. It is accessed by referring to the permanent link of the raw file.\n",
    "\n",
    "To read the data set, simply read in using pd.read_csv. The data is properly formatted using comma as delimiters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffa23ff3-cba3-408d-a67f-04a8626e2fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freq_1</th>\n",
       "      <th>Freq_2</th>\n",
       "      <th>Freq_3</th>\n",
       "      <th>Freq_4</th>\n",
       "      <th>Freq_5</th>\n",
       "      <th>Freq_6</th>\n",
       "      <th>Freq_7</th>\n",
       "      <th>Freq_8</th>\n",
       "      <th>Freq_9</th>\n",
       "      <th>Freq_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Freq_52</th>\n",
       "      <th>Freq_53</th>\n",
       "      <th>Freq_54</th>\n",
       "      <th>Freq_55</th>\n",
       "      <th>Freq_56</th>\n",
       "      <th>Freq_57</th>\n",
       "      <th>Freq_58</th>\n",
       "      <th>Freq_59</th>\n",
       "      <th>Freq_60</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Freq_1  Freq_2  Freq_3  Freq_4  Freq_5  Freq_6  Freq_7  Freq_8  Freq_9  \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "     Freq_10  ...  Freq_52  Freq_53  Freq_54  Freq_55  Freq_56  Freq_57  \\\n",
       "0     0.2111  ...   0.0027   0.0065   0.0159   0.0072   0.0167   0.0180   \n",
       "1     0.2872  ...   0.0084   0.0089   0.0048   0.0094   0.0191   0.0140   \n",
       "2     0.6194  ...   0.0232   0.0166   0.0095   0.0180   0.0244   0.0316   \n",
       "3     0.1264  ...   0.0121   0.0036   0.0150   0.0085   0.0073   0.0050   \n",
       "4     0.4459  ...   0.0031   0.0054   0.0105   0.0110   0.0015   0.0072   \n",
       "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "203   0.2684  ...   0.0116   0.0098   0.0199   0.0033   0.0101   0.0065   \n",
       "204   0.2154  ...   0.0061   0.0093   0.0135   0.0063   0.0063   0.0034   \n",
       "205   0.2529  ...   0.0160   0.0029   0.0051   0.0062   0.0089   0.0140   \n",
       "206   0.2354  ...   0.0086   0.0046   0.0126   0.0036   0.0035   0.0034   \n",
       "207   0.2354  ...   0.0146   0.0129   0.0047   0.0039   0.0061   0.0040   \n",
       "\n",
       "     Freq_58  Freq_59  Freq_60  Label  \n",
       "0     0.0084   0.0090   0.0032      R  \n",
       "1     0.0049   0.0052   0.0044      R  \n",
       "2     0.0164   0.0095   0.0078      R  \n",
       "3     0.0044   0.0040   0.0117      R  \n",
       "4     0.0048   0.0107   0.0094      R  \n",
       "..       ...      ...      ...    ...  \n",
       "203   0.0115   0.0193   0.0157      M  \n",
       "204   0.0032   0.0062   0.0067      M  \n",
       "205   0.0138   0.0077   0.0031      M  \n",
       "206   0.0079   0.0036   0.0048      M  \n",
       "207   0.0036   0.0061   0.0115      M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data = pd.read_csv (\"https://raw.githubusercontent.com/OminiCarlos/DSCI100_Group_14_Proposal_Mine_Finder/main/sonar.all-data.csv\")\n",
    "sonar_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47492f3e-1e64-40ab-876a-53569f84b0be",
   "metadata": {},
   "source": [
    "#### Data Cleaning and Wrangling\n",
    "After a thorough inspection, we can say that the data are already in clean format. Each column is a variable, each row is one observation and each value is a cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bb0e1b-a928-4022-af47-5493ee4ee317",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Summary Statistics\n",
    "To understand the content of the data set, we first take a look at sample size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46ea17d4-eba4-4c71-8dc4-da66b7020e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_observations = sonar_data.shape[0]\n",
    "nb_observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654aae6-a94d-4821-bd3c-552a9673611a",
   "metadata": {
    "tags": []
   },
   "source": [
    "208 is not a very big sample size, but it's enough to train our model. \n",
    "\n",
    "\n",
    "Secondly, we investigate the number of samples in each class, to verify if the sample is balanced. Imbalanced sample will let the dominant class hold the majority vote when it's not supposed to. This will give unnecessary favor to the majority class and hinder the model's accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9a5f6c6-9a76-4e8e-819a-344b500fb5ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    0.533654\n",
       "R    0.466346\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_breakdown = sonar_data[\"Label\"].value_counts(normalize = True)\n",
    "sample_breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc68faef-db1f-495f-95c2-0ca9bea91651",
   "metadata": {
    "tags": []
   },
   "source": [
    "We have 53% mine sample and 46% rock samples. Since the sample size is roughly the same, it is safe to say the sample is balanced. Therefore, we do not need to resample our data set. \n",
    "\n",
    "Since all the data are of the same type, which is the frequency, and that all the signal are in the same unit, the data is naturally centered. Therefore, we do not need to standardize the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c3ca7-1744-4a31-85fe-8fce98f42a20",
   "metadata": {},
   "source": [
    "#### Separate Test and Training Data\n",
    "Now that we have made sure the data set is legitimate, it's time to split the data into training and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24298639-a4ca-4181-865b-cf70dc9474db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freq_1</th>\n",
       "      <th>Freq_2</th>\n",
       "      <th>Freq_3</th>\n",
       "      <th>Freq_4</th>\n",
       "      <th>Freq_5</th>\n",
       "      <th>Freq_6</th>\n",
       "      <th>Freq_7</th>\n",
       "      <th>Freq_8</th>\n",
       "      <th>Freq_9</th>\n",
       "      <th>Freq_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Freq_52</th>\n",
       "      <th>Freq_53</th>\n",
       "      <th>Freq_54</th>\n",
       "      <th>Freq_55</th>\n",
       "      <th>Freq_56</th>\n",
       "      <th>Freq_57</th>\n",
       "      <th>Freq_58</th>\n",
       "      <th>Freq_59</th>\n",
       "      <th>Freq_60</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.0951</td>\n",
       "      <td>0.0836</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.0856</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.3110</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.2751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1606</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>0.3061</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.3823</td>\n",
       "      <td>0.3729</td>\n",
       "      <td>0.3583</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.0459</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.1798</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.1598</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.0721</td>\n",
       "      <td>0.1341</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>0.1902</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.3193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>0.1256</td>\n",
       "      <td>0.1323</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.2122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.1008</td>\n",
       "      <td>0.2252</td>\n",
       "      <td>0.2611</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.1668</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.3083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1054</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.2302</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Freq_1  Freq_2  Freq_3  Freq_4  Freq_5  Freq_6  Freq_7  Freq_8  Freq_9  \\\n",
       "63   0.0067  0.0096  0.0024  0.0058  0.0197  0.0618  0.0432  0.0951  0.0836   \n",
       "87   0.0856  0.0454  0.0382  0.0203  0.0385  0.0534  0.2140  0.3110  0.2837   \n",
       "158  0.0107  0.0453  0.0289  0.0713  0.1075  0.1019  0.1606  0.2119  0.3061   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "91   0.0253  0.0808  0.0507  0.0244  0.1724  0.3823  0.3729  0.3583  0.3429   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "93   0.0459  0.0437  0.0347  0.0456  0.0067  0.0890  0.1798  0.1741  0.1598   \n",
       "200  0.0131  0.0387  0.0329  0.0078  0.0721  0.1341  0.1626  0.1902  0.2610   \n",
       "123  0.0270  0.0163  0.0341  0.0247  0.0822  0.1256  0.1323  0.1584  0.2017   \n",
       "130  0.0443  0.0446  0.0235  0.1008  0.2252  0.2611  0.2061  0.1668  0.1801   \n",
       "82   0.0409  0.0421  0.0573  0.0130  0.0183  0.1019  0.1054  0.1070  0.2302   \n",
       "\n",
       "     Freq_10  ...  Freq_52  Freq_53  Freq_54  Freq_55  Freq_56  Freq_57  \\\n",
       "63    0.1180  ...   0.0048   0.0023   0.0020   0.0040   0.0019   0.0034   \n",
       "87    0.2751  ...   0.0172   0.0138   0.0079   0.0037   0.0051   0.0258   \n",
       "158   0.2936  ...   0.0164   0.0120   0.0113   0.0021   0.0097   0.0072   \n",
       "1     0.2872  ...   0.0084   0.0089   0.0048   0.0094   0.0191   0.0140   \n",
       "91    0.2197  ...   0.0178   0.0073   0.0079   0.0038   0.0116   0.0033   \n",
       "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "93    0.1408  ...   0.0067   0.0032   0.0109   0.0164   0.0151   0.0070   \n",
       "200   0.3193  ...   0.0150   0.0076   0.0032   0.0037   0.0071   0.0040   \n",
       "123   0.2122  ...   0.0189   0.0204   0.0085   0.0043   0.0092   0.0138   \n",
       "130   0.3083  ...   0.0274   0.0205   0.0141   0.0185   0.0055   0.0045   \n",
       "82    0.2259  ...   0.0028   0.0036   0.0105   0.0120   0.0087   0.0061   \n",
       "\n",
       "     Freq_58  Freq_59  Freq_60  Label  \n",
       "63    0.0034   0.0051   0.0031      R  \n",
       "87    0.0102   0.0037   0.0037      R  \n",
       "158   0.0060   0.0017   0.0036      M  \n",
       "1     0.0049   0.0052   0.0044      R  \n",
       "91    0.0039   0.0081   0.0053      R  \n",
       "..       ...      ...      ...    ...  \n",
       "93    0.0085   0.0117   0.0056      R  \n",
       "200   0.0009   0.0015   0.0085      M  \n",
       "123   0.0094   0.0105   0.0093      M  \n",
       "130   0.0115   0.0152   0.0100      M  \n",
       "82    0.0061   0.0030   0.0078      R  \n",
       "\n",
       "[156 rows x 61 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random state\n",
    "np.random.seed(1024)\n",
    "\n",
    "sonar_train, sonar_test = train_test_split(\n",
    "    sonar_data, train_size=0.75, stratify=sonar_data[\"Label\"]\n",
    ")\n",
    "\n",
    "sonar_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "feb702f9-7ca8-44e3-9027-9e45887757e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    0.532051\n",
       "R    0.467949\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_breakdown = sonar_train[\"Label\"].value_counts(normalize = True)\n",
    "train_breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b93f2c2-225e-4d5a-9f92-457746c82b79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    0.538462\n",
       "R    0.461538\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_breakdown = sonar_test[\"Label\"].value_counts(normalize = True)\n",
    "test_breakdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b1a25-6844-452c-8c91-e1f70c6d717a",
   "metadata": {},
   "source": [
    "The train and test set are roughly balanced, too. Now we can move on. To separate the predictor columns from the label column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7055455-a944-402a-85ff-05c9deba284f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63     R\n",
       "87     R\n",
       "158    M\n",
       "1      R\n",
       "91     R\n",
       "      ..\n",
       "93     R\n",
       "200    M\n",
       "123    M\n",
       "130    M\n",
       "82     R\n",
       "Name: Label, Length: 156, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate predictors and labels\n",
    "X_train = sonar_train.drop('Label', axis=1)\n",
    "y_train = sonar_train['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e30bfc7-78a1-491b-8db5-3ff4995853a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate predictors and labels\n",
    "X_test = sonar_test.drop('Label', axis=1)\n",
    "y_test = sonar_test['Label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae079708-5b57-4d2e-8d49-bd06441c6427",
   "metadata": {},
   "source": [
    "### Exploratory Visualization\n",
    "\n",
    "I will group my data into 2 sets: Mine and Rock, to see if there is a visible pattern with their sonar profile. First I will group my data set by labels, then I will aggregate my data by calculating the mean value of each frequency. After that, I will plot the sonar profile using bar plots for both signals, to compare the intensity at each frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90971f46-36f1-42a0-8a03-d529c81eb40e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Freq_1</th>\n",
       "      <th>Freq_2</th>\n",
       "      <th>Freq_3</th>\n",
       "      <th>Freq_4</th>\n",
       "      <th>Freq_5</th>\n",
       "      <th>Freq_6</th>\n",
       "      <th>Freq_7</th>\n",
       "      <th>Freq_8</th>\n",
       "      <th>Freq_9</th>\n",
       "      <th>...</th>\n",
       "      <th>Freq_51</th>\n",
       "      <th>Freq_52</th>\n",
       "      <th>Freq_53</th>\n",
       "      <th>Freq_54</th>\n",
       "      <th>Freq_55</th>\n",
       "      <th>Freq_56</th>\n",
       "      <th>Freq_57</th>\n",
       "      <th>Freq_58</th>\n",
       "      <th>Freq_59</th>\n",
       "      <th>Freq_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.034478</td>\n",
       "      <td>0.046443</td>\n",
       "      <td>0.054616</td>\n",
       "      <td>0.068734</td>\n",
       "      <td>0.089508</td>\n",
       "      <td>0.114306</td>\n",
       "      <td>0.127623</td>\n",
       "      <td>0.149060</td>\n",
       "      <td>0.220994</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019617</td>\n",
       "      <td>0.016706</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.012099</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>0.008971</td>\n",
       "      <td>0.007801</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.008417</td>\n",
       "      <td>0.006922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>0.023474</td>\n",
       "      <td>0.029532</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.039905</td>\n",
       "      <td>0.062152</td>\n",
       "      <td>0.098152</td>\n",
       "      <td>0.117866</td>\n",
       "      <td>0.121126</td>\n",
       "      <td>0.140244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012119</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>0.009723</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.008041</td>\n",
       "      <td>0.007697</td>\n",
       "      <td>0.007526</td>\n",
       "      <td>0.006670</td>\n",
       "      <td>0.006537</td>\n",
       "      <td>0.006077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label    Freq_1    Freq_2    Freq_3    Freq_4    Freq_5    Freq_6    Freq_7  \\\n",
       "0     M  0.034478  0.046443  0.054616  0.068734  0.089508  0.114306  0.127623   \n",
       "1     R  0.023474  0.029532  0.035075  0.039905  0.062152  0.098152  0.117866   \n",
       "\n",
       "     Freq_8    Freq_9  ...   Freq_51   Freq_52   Freq_53   Freq_54   Freq_55  \\\n",
       "0  0.149060  0.220994  ...  0.019617  0.016706  0.011980  0.012099  0.009931   \n",
       "1  0.121126  0.140244  ...  0.012119  0.010173  0.009723  0.008992  0.008041   \n",
       "\n",
       "    Freq_56   Freq_57   Freq_58   Freq_59   Freq_60  \n",
       "0  0.008971  0.007801  0.008966  0.008417  0.006922  \n",
       "1  0.007697  0.007526  0.006670  0.006537  0.006077  \n",
       "\n",
       "[2 rows x 61 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snoar_data_agg = sonar_train.groupby([\"Label\"]).mean().reset_index()\n",
    "snoar_data_agg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d8abe9-0f34-4f83-8ba1-484859680d05",
   "metadata": {},
   "source": [
    "We can see that the signal of Mine is different from that of rocks. For example,  the intensity of Freq_9 of the Mine is significantly higher than that of the rock. Now it's time to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15b1a7fb-ecb7-4a0f-a536-a13393bbe16b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>Freq_1</td>\n",
       "      <td>0.034478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>Freq_1</td>\n",
       "      <td>0.023474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>Freq_2</td>\n",
       "      <td>0.046443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R</td>\n",
       "      <td>Freq_2</td>\n",
       "      <td>0.029532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>Freq_3</td>\n",
       "      <td>0.054616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>R</td>\n",
       "      <td>Freq_58</td>\n",
       "      <td>0.006670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>M</td>\n",
       "      <td>Freq_59</td>\n",
       "      <td>0.008417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>R</td>\n",
       "      <td>Freq_59</td>\n",
       "      <td>0.006537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>M</td>\n",
       "      <td>Freq_60</td>\n",
       "      <td>0.006922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>R</td>\n",
       "      <td>Freq_60</td>\n",
       "      <td>0.006077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label Frequency  Intensity\n",
       "0       M    Freq_1   0.034478\n",
       "1       R    Freq_1   0.023474\n",
       "2       M    Freq_2   0.046443\n",
       "3       R    Freq_2   0.029532\n",
       "4       M    Freq_3   0.054616\n",
       "..    ...       ...        ...\n",
       "115     R   Freq_58   0.006670\n",
       "116     M   Freq_59   0.008417\n",
       "117     R   Freq_59   0.006537\n",
       "118     M   Freq_60   0.006922\n",
       "119     R   Freq_60   0.006077\n",
       "\n",
       "[120 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort columns\n",
    "sorted_cols = ['Label'] + sorted(snoar_data_agg.columns[1:], key=lambda x: int(x.split('_')[1]))\n",
    "\n",
    "# melt data into long format\n",
    "sonar_agg_melt = snoar_data_agg.melt(id_vars = \"Label\",\n",
    "                                     var_name=\"Frequency\",\n",
    "                                     value_name = \"Intensity\"\n",
    "                                    )\n",
    "sonar_agg_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d932fbd5-f6e6-44f0-ba3e-770986aa5cca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-0b5ee370bd2e4554a9321b729f6d1d6b\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-0b5ee370bd2e4554a9321b729f6d1d6b\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-0b5ee370bd2e4554a9321b729f6d1d6b\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9d14fd62e7bd7b1f9ae969177417026e\"}, \"mark\": \"bar\", \"encoding\": {\"color\": {\"field\": \"Label\", \"type\": \"nominal\"}, \"x\": {\"field\": \"Frequency\", \"sort\": [\"Freq_1\", \"Freq_2\", \"Freq_3\", \"Freq_4\", \"Freq_5\", \"Freq_6\", \"Freq_7\", \"Freq_8\", \"Freq_9\", \"Freq_10\", \"Freq_11\", \"Freq_12\", \"Freq_13\", \"Freq_14\", \"Freq_15\", \"Freq_16\", \"Freq_17\", \"Freq_18\", \"Freq_19\", \"Freq_20\", \"Freq_21\", \"Freq_22\", \"Freq_23\", \"Freq_24\", \"Freq_25\", \"Freq_26\", \"Freq_27\", \"Freq_28\", \"Freq_29\", \"Freq_30\", \"Freq_31\", \"Freq_32\", \"Freq_33\", \"Freq_34\", \"Freq_35\", \"Freq_36\", \"Freq_37\", \"Freq_38\", \"Freq_39\", \"Freq_40\", \"Freq_41\", \"Freq_42\", \"Freq_43\", \"Freq_44\", \"Freq_45\", \"Freq_46\", \"Freq_47\", \"Freq_48\", \"Freq_49\", \"Freq_50\", \"Freq_51\", \"Freq_52\", \"Freq_53\", \"Freq_54\", \"Freq_55\", \"Freq_56\", \"Freq_57\", \"Freq_58\", \"Freq_59\", \"Freq_60\"], \"type\": \"nominal\"}, \"y\": {\"field\": \"Intensity\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-9d14fd62e7bd7b1f9ae969177417026e\": [{\"Label\": \"M\", \"Frequency\": \"Freq_1\", \"Intensity\": 0.034478313253012045}, {\"Label\": \"R\", \"Frequency\": \"Freq_1\", \"Intensity\": 0.023473972602739725}, {\"Label\": \"M\", \"Frequency\": \"Freq_2\", \"Intensity\": 0.046443373493975905}, {\"Label\": \"R\", \"Frequency\": \"Freq_2\", \"Intensity\": 0.029531506849315072}, {\"Label\": \"M\", \"Frequency\": \"Freq_3\", \"Intensity\": 0.054615662650602415}, {\"Label\": \"R\", \"Frequency\": \"Freq_3\", \"Intensity\": 0.035075342465753424}, {\"Label\": \"M\", \"Frequency\": \"Freq_4\", \"Intensity\": 0.06873373493975904}, {\"Label\": \"R\", \"Frequency\": \"Freq_4\", \"Intensity\": 0.0399054794520548}, {\"Label\": \"M\", \"Frequency\": \"Freq_5\", \"Intensity\": 0.08950843373493976}, {\"Label\": \"R\", \"Frequency\": \"Freq_5\", \"Intensity\": 0.062152054794520545}, {\"Label\": \"M\", \"Frequency\": \"Freq_6\", \"Intensity\": 0.11430602409638553}, {\"Label\": \"R\", \"Frequency\": \"Freq_6\", \"Intensity\": 0.09815205479452055}, {\"Label\": \"M\", \"Frequency\": \"Freq_7\", \"Intensity\": 0.12762289156626508}, {\"Label\": \"R\", \"Frequency\": \"Freq_7\", \"Intensity\": 0.11786575342465754}, {\"Label\": \"M\", \"Frequency\": \"Freq_8\", \"Intensity\": 0.14906024096385542}, {\"Label\": \"R\", \"Frequency\": \"Freq_8\", \"Intensity\": 0.12112602739726028}, {\"Label\": \"M\", \"Frequency\": \"Freq_9\", \"Intensity\": 0.22099397590361447}, {\"Label\": \"R\", \"Frequency\": \"Freq_9\", \"Intensity\": 0.14024383561643836}, {\"Label\": \"M\", \"Frequency\": \"Freq_10\", \"Intensity\": 0.2550096385542169}, {\"Label\": \"R\", \"Frequency\": \"Freq_10\", \"Intensity\": 0.15986301369863012}, {\"Label\": \"M\", \"Frequency\": \"Freq_11\", \"Intensity\": 0.2923096385542169}, {\"Label\": \"R\", \"Frequency\": \"Freq_11\", \"Intensity\": 0.17835616438356164}, {\"Label\": \"M\", \"Frequency\": \"Freq_12\", \"Intensity\": 0.3016168674698795}, {\"Label\": \"R\", \"Frequency\": \"Freq_12\", \"Intensity\": 0.1974178082191781}, {\"Label\": \"M\", \"Frequency\": \"Freq_13\", \"Intensity\": 0.31312289156626505}, {\"Label\": \"R\", \"Frequency\": \"Freq_13\", \"Intensity\": 0.23304794520547945}, {\"Label\": \"M\", \"Frequency\": \"Freq_14\", \"Intensity\": 0.3297457831325301}, {\"Label\": \"R\", \"Frequency\": \"Freq_14\", \"Intensity\": 0.2790904109589041}, {\"Label\": \"M\", \"Frequency\": \"Freq_15\", \"Intensity\": 0.34246506024096385}, {\"Label\": \"R\", \"Frequency\": \"Freq_15\", \"Intensity\": 0.3125027397260274}, {\"Label\": \"M\", \"Frequency\": \"Freq_16\", \"Intensity\": 0.3898951807228916}, {\"Label\": \"R\", \"Frequency\": \"Freq_16\", \"Intensity\": 0.3698835616438356}, {\"Label\": \"M\", \"Frequency\": \"Freq_17\", \"Intensity\": 0.4287614457831326}, {\"Label\": \"R\", \"Frequency\": \"Freq_17\", \"Intensity\": 0.40483972602739726}, {\"Label\": \"M\", \"Frequency\": \"Freq_18\", \"Intensity\": 0.47582289156626506}, {\"Label\": \"R\", \"Frequency\": \"Freq_18\", \"Intensity\": 0.44121369863013693}, {\"Label\": \"M\", \"Frequency\": \"Freq_19\", \"Intensity\": 0.5510626506024097}, {\"Label\": \"R\", \"Frequency\": \"Freq_19\", \"Intensity\": 0.46984246575342464}, {\"Label\": \"M\", \"Frequency\": \"Freq_20\", \"Intensity\": 0.633189156626506}, {\"Label\": \"R\", \"Frequency\": \"Freq_20\", \"Intensity\": 0.5017904109589041}, {\"Label\": \"M\", \"Frequency\": \"Freq_21\", \"Intensity\": 0.6796409638554217}, {\"Label\": \"R\", \"Frequency\": \"Freq_21\", \"Intensity\": 0.5462698630136986}, {\"Label\": \"M\", \"Frequency\": \"Freq_22\", \"Intensity\": 0.6686240963855422}, {\"Label\": \"R\", \"Frequency\": \"Freq_22\", \"Intensity\": 0.5883054794520548}, {\"Label\": \"M\", \"Frequency\": \"Freq_23\", \"Intensity\": 0.6600180722891567}, {\"Label\": \"R\", \"Frequency\": \"Freq_23\", \"Intensity\": 0.6340753424657535}, {\"Label\": \"M\", \"Frequency\": \"Freq_24\", \"Intensity\": 0.6727361445783132}, {\"Label\": \"R\", \"Frequency\": \"Freq_24\", \"Intensity\": 0.6610479452054795}, {\"Label\": \"M\", \"Frequency\": \"Freq_25\", \"Intensity\": 0.6602530120481928}, {\"Label\": \"R\", \"Frequency\": \"Freq_25\", \"Intensity\": 0.6709232876712329}, {\"Label\": \"M\", \"Frequency\": \"Freq_26\", \"Intensity\": 0.6840373493975904}, {\"Label\": \"R\", \"Frequency\": \"Freq_26\", \"Intensity\": 0.696182191780822}, {\"Label\": \"M\", \"Frequency\": \"Freq_27\", \"Intensity\": 0.6935385542168674}, {\"Label\": \"R\", \"Frequency\": \"Freq_27\", \"Intensity\": 0.682858904109589}, {\"Label\": \"M\", \"Frequency\": \"Freq_28\", \"Intensity\": 0.6904963855421686}, {\"Label\": \"R\", \"Frequency\": \"Freq_28\", \"Intensity\": 0.6694520547945205}, {\"Label\": \"M\", \"Frequency\": \"Freq_29\", \"Intensity\": 0.6372457831325301}, {\"Label\": \"R\", \"Frequency\": \"Freq_29\", \"Intensity\": 0.6383232876712329}, {\"Label\": \"M\", \"Frequency\": \"Freq_30\", \"Intensity\": 0.5668578313253012}, {\"Label\": \"R\", \"Frequency\": \"Freq_30\", \"Intensity\": 0.5827424657534246}, {\"Label\": \"M\", \"Frequency\": \"Freq_31\", \"Intensity\": 0.46540120481927716}, {\"Label\": \"R\", \"Frequency\": \"Freq_31\", \"Intensity\": 0.5220671232876712}, {\"Label\": \"M\", \"Frequency\": \"Freq_32\", \"Intensity\": 0.4182542168674699}, {\"Label\": \"R\", \"Frequency\": \"Freq_32\", \"Intensity\": 0.4410534246575342}, {\"Label\": \"M\", \"Frequency\": \"Freq_33\", \"Intensity\": 0.39511807228915663}, {\"Label\": \"R\", \"Frequency\": \"Freq_33\", \"Intensity\": 0.4297260273972603}, {\"Label\": \"M\", \"Frequency\": \"Freq_34\", \"Intensity\": 0.369489156626506}, {\"Label\": \"R\", \"Frequency\": \"Freq_34\", \"Intensity\": 0.4231082191780822}, {\"Label\": \"M\", \"Frequency\": \"Freq_35\", \"Intensity\": 0.3434301204819277}, {\"Label\": \"R\", \"Frequency\": \"Freq_35\", \"Intensity\": 0.4293178082191781}, {\"Label\": \"M\", \"Frequency\": \"Freq_36\", \"Intensity\": 0.32447951807228914}, {\"Label\": \"R\", \"Frequency\": \"Freq_36\", \"Intensity\": 0.43301917808219176}, {\"Label\": \"M\", \"Frequency\": \"Freq_37\", \"Intensity\": 0.3226349397590362}, {\"Label\": \"R\", \"Frequency\": \"Freq_37\", \"Intensity\": 0.39673972602739727}, {\"Label\": \"M\", \"Frequency\": \"Freq_38\", \"Intensity\": 0.3318397590361446}, {\"Label\": \"R\", \"Frequency\": \"Freq_38\", \"Intensity\": 0.33786301369863014}, {\"Label\": \"M\", \"Frequency\": \"Freq_39\", \"Intensity\": 0.32790963855421684}, {\"Label\": \"R\", \"Frequency\": \"Freq_39\", \"Intensity\": 0.30229041095890413}, {\"Label\": \"M\", \"Frequency\": \"Freq_40\", \"Intensity\": 0.29749036144578317}, {\"Label\": \"R\", \"Frequency\": \"Freq_40\", \"Intensity\": 0.30912602739726025}, {\"Label\": \"M\", \"Frequency\": \"Freq_41\", \"Intensity\": 0.2827313253012048}, {\"Label\": \"R\", \"Frequency\": \"Freq_41\", \"Intensity\": 0.2847369863013699}, {\"Label\": \"M\", \"Frequency\": \"Freq_42\", \"Intensity\": 0.29394698795180724}, {\"Label\": \"R\", \"Frequency\": \"Freq_42\", \"Intensity\": 0.24636575342465752}, {\"Label\": \"M\", \"Frequency\": \"Freq_43\", \"Intensity\": 0.2673012048192771}, {\"Label\": \"R\", \"Frequency\": \"Freq_43\", \"Intensity\": 0.21116986301369864}, {\"Label\": \"M\", \"Frequency\": \"Freq_44\", \"Intensity\": 0.24496867469879519}, {\"Label\": \"R\", \"Frequency\": \"Freq_44\", \"Intensity\": 0.17914657534246575}, {\"Label\": \"M\", \"Frequency\": \"Freq_45\", \"Intensity\": 0.2386710843373494}, {\"Label\": \"R\", \"Frequency\": \"Freq_45\", \"Intensity\": 0.1496027397260274}, {\"Label\": \"M\", \"Frequency\": \"Freq_46\", \"Intensity\": 0.187644578313253}, {\"Label\": \"R\", \"Frequency\": \"Freq_46\", \"Intensity\": 0.11974109589041095}, {\"Label\": \"M\", \"Frequency\": \"Freq_47\", \"Intensity\": 0.13948674698795183}, {\"Label\": \"R\", \"Frequency\": \"Freq_47\", \"Intensity\": 0.09486027397260274}, {\"Label\": \"M\", \"Frequency\": \"Freq_48\", \"Intensity\": 0.11009879518072288}, {\"Label\": \"R\", \"Frequency\": \"Freq_48\", \"Intensity\": 0.07023287671232877}, {\"Label\": \"M\", \"Frequency\": \"Freq_49\", \"Intensity\": 0.06152289156626506}, {\"Label\": \"R\", \"Frequency\": \"Freq_49\", \"Intensity\": 0.03944520547945206}, {\"Label\": \"M\", \"Frequency\": \"Freq_50\", \"Intensity\": 0.021238554216867468}, {\"Label\": \"R\", \"Frequency\": \"Freq_50\", \"Intensity\": 0.017410958904109586}, {\"Label\": \"M\", \"Frequency\": \"Freq_51\", \"Intensity\": 0.01961686746987952}, {\"Label\": \"R\", \"Frequency\": \"Freq_51\", \"Intensity\": 0.01211917808219178}, {\"Label\": \"M\", \"Frequency\": \"Freq_52\", \"Intensity\": 0.016706024096385542}, {\"Label\": \"R\", \"Frequency\": \"Freq_52\", \"Intensity\": 0.010172602739726028}, {\"Label\": \"M\", \"Frequency\": \"Freq_53\", \"Intensity\": 0.011979518072289155}, {\"Label\": \"R\", \"Frequency\": \"Freq_53\", \"Intensity\": 0.009723287671232877}, {\"Label\": \"M\", \"Frequency\": \"Freq_54\", \"Intensity\": 0.01209879518072289}, {\"Label\": \"R\", \"Frequency\": \"Freq_54\", \"Intensity\": 0.008991780821917808}, {\"Label\": \"M\", \"Frequency\": \"Freq_55\", \"Intensity\": 0.00993132530120482}, {\"Label\": \"R\", \"Frequency\": \"Freq_55\", \"Intensity\": 0.008041095890410958}, {\"Label\": \"M\", \"Frequency\": \"Freq_56\", \"Intensity\": 0.008971084337349397}, {\"Label\": \"R\", \"Frequency\": \"Freq_56\", \"Intensity\": 0.0076972602739726025}, {\"Label\": \"M\", \"Frequency\": \"Freq_57\", \"Intensity\": 0.007801204819277108}, {\"Label\": \"R\", \"Frequency\": \"Freq_57\", \"Intensity\": 0.007526027397260274}, {\"Label\": \"M\", \"Frequency\": \"Freq_58\", \"Intensity\": 0.008966265060240964}, {\"Label\": \"R\", \"Frequency\": \"Freq_58\", \"Intensity\": 0.00666986301369863}, {\"Label\": \"M\", \"Frequency\": \"Freq_59\", \"Intensity\": 0.008416867469879519}, {\"Label\": \"R\", \"Frequency\": \"Freq_59\", \"Intensity\": 0.006536986301369863}, {\"Label\": \"M\", \"Frequency\": \"Freq_60\", \"Intensity\": 0.006921686746987952}, {\"Label\": \"R\", \"Frequency\": \"Freq_60\", \"Intensity\": 0.0060767123287671235}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_bar_plot = alt.Chart(sonar_agg_melt).mark_bar().encode(\n",
    "    x = alt.X(\"Frequency\", sort=sorted_cols[1:]),\n",
    "    y = alt.Y(\"Intensity\"),\n",
    "    color = \"Label\"\n",
    ")\n",
    "\n",
    "agg_bar_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eb9d77-c03b-4da4-85e1-9af16d42c3ea",
   "metadata": {},
   "source": [
    "As can be seen in the bar plot, the intensity of the rock signal is generally weaker than that of the mines. This difference is very obvious in the region between Frequency 18 -31. This pattern tells us it is possible to distinguish a rock and a mine with the sonar signal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96850ede-3643-4823-8269-56bc80019988",
   "metadata": {},
   "source": [
    "### Finding the Best K for the Classifier\n",
    "Now it's the time to search for the best parameter K for our Knn model. To do this, we need to first specify the parameters of the SearchGridCV function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96ba87e1-e21a-44c5-8686-6c00829c469b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert M (Mine) to 1 and R (Rock) to 0, so the data can be used by the model.\n",
    "y_train = y_train.replace({'M': 1, 'R': 0})\n",
    "y_test = y_test.replace({'M': 1, 'R': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a96c0c8-af3b-4c82-8dbe-8a02d8602d88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Specify the estimator. \n",
    "# Since the data is naturally centered, we don't need to standardize it\n",
    "knn_spec =  KNeighborsClassifier()\n",
    "display (knn_spec.get_params()) # get the parameter that specifies the No. of neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576cef9e-811c-4a7d-b849-8c792e36e085",
   "metadata": {},
   "source": [
    "We will create a search grid by plugging K = 2 to 20 in the 'n_neighbors' parameter. \n",
    " \n",
    "Then we will perform grid search with 5-fold cross-validation to find the best value for k (number of neighbors).\n",
    "\n",
    "Here we choose **recall** as our score, because we want to have as little false negative for our model as possible. The reason is that we water mines are dangerous. The water mines that we fail to detect could potentially cause damage to ships and even cost lives. On the other hand, when we have false positive, we risk wasting peoples time to verify if the object is really a mine, which is acceptable. \n",
    "\n",
    "Lastly, we will report the performance of the model in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c1b5f09-c1e8-4c30-a305-5edbf06417ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>2</td>\n",
       "      <td>{'n_neighbors': 2}</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759559</td>\n",
       "      <td>0.084017</td>\n",
       "      <td>11</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.858345</td>\n",
       "      <td>0.032712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>3</td>\n",
       "      <td>{'n_neighbors': 3}</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879412</td>\n",
       "      <td>0.075682</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.940299</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.924242</td>\n",
       "      <td>0.912619</td>\n",
       "      <td>0.022241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.011055</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>4</td>\n",
       "      <td>{'n_neighbors': 4}</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771324</td>\n",
       "      <td>0.139714</td>\n",
       "      <td>8</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.867436</td>\n",
       "      <td>0.020279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.006304</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>5</td>\n",
       "      <td>{'n_neighbors': 5}</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843382</td>\n",
       "      <td>0.073220</td>\n",
       "      <td>2</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.900678</td>\n",
       "      <td>0.025961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003286</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>6</td>\n",
       "      <td>{'n_neighbors': 6}</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746324</td>\n",
       "      <td>0.102889</td>\n",
       "      <td>13</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.023633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>7</td>\n",
       "      <td>{'n_neighbors': 7}</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819853</td>\n",
       "      <td>0.084415</td>\n",
       "      <td>5</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.893939</td>\n",
       "      <td>0.876572</td>\n",
       "      <td>0.017051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>8</td>\n",
       "      <td>{'n_neighbors': 8}</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701471</td>\n",
       "      <td>0.136186</td>\n",
       "      <td>18</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.798010</td>\n",
       "      <td>0.050944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>9</td>\n",
       "      <td>{'n_neighbors': 9}</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.820588</td>\n",
       "      <td>0.122761</td>\n",
       "      <td>4</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.855360</td>\n",
       "      <td>0.035524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797059</td>\n",
       "      <td>0.141119</td>\n",
       "      <td>6</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.776934</td>\n",
       "      <td>0.041870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>11</td>\n",
       "      <td>{'n_neighbors': 11}</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832353</td>\n",
       "      <td>0.100781</td>\n",
       "      <td>3</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.880597</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.834193</td>\n",
       "      <td>0.042175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.005641</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>12</td>\n",
       "      <td>{'n_neighbors': 12}</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736765</td>\n",
       "      <td>0.132120</td>\n",
       "      <td>14</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.767978</td>\n",
       "      <td>0.038272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>13</td>\n",
       "      <td>{'n_neighbors': 13}</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760294</td>\n",
       "      <td>0.118595</td>\n",
       "      <td>9</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.810131</td>\n",
       "      <td>0.025224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.001622</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>14</td>\n",
       "      <td>{'n_neighbors': 14}</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711765</td>\n",
       "      <td>0.171287</td>\n",
       "      <td>17</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.762008</td>\n",
       "      <td>0.026354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.007861</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>15</td>\n",
       "      <td>{'n_neighbors': 15}</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.759559</td>\n",
       "      <td>0.132140</td>\n",
       "      <td>11</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.831389</td>\n",
       "      <td>0.023673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>16</td>\n",
       "      <td>{'n_neighbors': 16}</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.736029</td>\n",
       "      <td>0.144283</td>\n",
       "      <td>15</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.771190</td>\n",
       "      <td>0.042628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002798</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>17</td>\n",
       "      <td>{'n_neighbors': 17}</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795588</td>\n",
       "      <td>0.142306</td>\n",
       "      <td>7</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.865672</td>\n",
       "      <td>0.805970</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.840389</td>\n",
       "      <td>0.024179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>18</td>\n",
       "      <td>{'n_neighbors': 18}</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700735</td>\n",
       "      <td>0.189523</td>\n",
       "      <td>19</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.768024</td>\n",
       "      <td>0.021015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>19</td>\n",
       "      <td>{'n_neighbors': 19}</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760294</td>\n",
       "      <td>0.188992</td>\n",
       "      <td>10</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.803030</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.813388</td>\n",
       "      <td>0.033137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003968</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>20</td>\n",
       "      <td>{'n_neighbors': 20}</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.6250</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724265</td>\n",
       "      <td>0.189529</td>\n",
       "      <td>16</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.686567</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.756128</td>\n",
       "      <td>0.038805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.002997      0.000396         0.005378        0.000243   \n",
       "1        0.003133      0.000397         0.005887        0.000876   \n",
       "2        0.008446      0.011055         0.005346        0.000480   \n",
       "3        0.003445      0.000465         0.006304        0.000757   \n",
       "4        0.003286      0.000423         0.006063        0.000704   \n",
       "5        0.002771      0.000033         0.005215        0.000090   \n",
       "6        0.002768      0.000034         0.005265        0.000052   \n",
       "7        0.002850      0.000145         0.005388        0.000247   \n",
       "8        0.002764      0.000035         0.005320        0.000251   \n",
       "9        0.002908      0.000299         0.005162        0.000072   \n",
       "10       0.002988      0.000441         0.005641        0.000626   \n",
       "11       0.002892      0.000148         0.005625        0.000413   \n",
       "12       0.003659      0.001622         0.005399        0.000259   \n",
       "13       0.003241      0.000563         0.007861        0.004796   \n",
       "14       0.002835      0.000111         0.005700        0.000382   \n",
       "15       0.002798      0.000109         0.005288        0.000137   \n",
       "16       0.004036      0.001569         0.006265        0.000937   \n",
       "17       0.002811      0.000126         0.005464        0.000343   \n",
       "18       0.003968      0.001093         0.006222        0.000897   \n",
       "\n",
       "   param_n_neighbors               params  split0_test_score  \\\n",
       "0                  2   {'n_neighbors': 2}           0.647059   \n",
       "1                  3   {'n_neighbors': 3}           0.764706   \n",
       "2                  4   {'n_neighbors': 4}           0.588235   \n",
       "3                  5   {'n_neighbors': 5}           0.764706   \n",
       "4                  6   {'n_neighbors': 6}           0.588235   \n",
       "5                  7   {'n_neighbors': 7}           0.705882   \n",
       "6                  8   {'n_neighbors': 8}           0.470588   \n",
       "7                  9   {'n_neighbors': 9}           0.588235   \n",
       "8                 10  {'n_neighbors': 10}           0.529412   \n",
       "9                 11  {'n_neighbors': 11}           0.647059   \n",
       "10                12  {'n_neighbors': 12}           0.529412   \n",
       "11                13  {'n_neighbors': 13}           0.588235   \n",
       "12                14  {'n_neighbors': 14}           0.470588   \n",
       "13                15  {'n_neighbors': 15}           0.588235   \n",
       "14                16  {'n_neighbors': 16}           0.529412   \n",
       "15                17  {'n_neighbors': 17}           0.647059   \n",
       "16                18  {'n_neighbors': 18}           0.470588   \n",
       "17                19  {'n_neighbors': 19}           0.470588   \n",
       "18                20  {'n_neighbors': 20}           0.411765   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  ...  \\\n",
       "0              0.6875             0.8750           0.823529  ...   \n",
       "1              0.8125             0.9375           0.941176  ...   \n",
       "2              0.6250             0.9375           0.823529  ...   \n",
       "3              0.7500             0.9375           0.882353  ...   \n",
       "4              0.6875             0.7500           0.882353  ...   \n",
       "5              0.7500             0.9375           0.882353  ...   \n",
       "6              0.7500             0.8750           0.764706  ...   \n",
       "7              0.8125             0.9375           0.882353  ...   \n",
       "8              0.8125             0.9375           0.882353  ...   \n",
       "9              0.8125             0.9375           0.882353  ...   \n",
       "10             0.6875             0.9375           0.764706  ...   \n",
       "11             0.6875             0.9375           0.764706  ...   \n",
       "12             0.5625             0.9375           0.764706  ...   \n",
       "13             0.6250             0.9375           0.823529  ...   \n",
       "14             0.6250             0.9375           0.764706  ...   \n",
       "15             0.6250             1.0000           0.882353  ...   \n",
       "16             0.5625             1.0000           0.647059  ...   \n",
       "17             0.6250             1.0000           0.823529  ...   \n",
       "18             0.6250             0.9375           0.764706  ...   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0          0.759559        0.084017               11            0.848485   \n",
       "1          0.879412        0.075682                1            0.878788   \n",
       "2          0.771324        0.139714                8            0.833333   \n",
       "3          0.843382        0.073220                2            0.878788   \n",
       "4          0.746324        0.102889               13            0.787879   \n",
       "5          0.819853        0.084415                5            0.863636   \n",
       "6          0.701471        0.136186               18            0.696970   \n",
       "7          0.820588        0.122761                4            0.818182   \n",
       "8          0.797059        0.141119                6            0.696970   \n",
       "9          0.832353        0.100781                3            0.757576   \n",
       "10         0.736765        0.132120               14            0.696970   \n",
       "11         0.760294        0.118595                9            0.772727   \n",
       "12         0.711765        0.171287               17            0.712121   \n",
       "13         0.759559        0.132140               11            0.803030   \n",
       "14         0.736029        0.144283               15            0.712121   \n",
       "15         0.795588        0.142306                7            0.818182   \n",
       "16         0.700735        0.189523               19            0.727273   \n",
       "17         0.760294        0.188992               10            0.803030   \n",
       "18         0.724265        0.189529               16            0.772727   \n",
       "\n",
       "    split1_train_score  split2_train_score  split3_train_score  \\\n",
       "0             0.910448            0.835821            0.818182   \n",
       "1             0.940299            0.895522            0.924242   \n",
       "2             0.865672            0.880597            0.893939   \n",
       "3             0.865672            0.910448            0.939394   \n",
       "4             0.820896            0.791045            0.848485   \n",
       "5             0.850746            0.880597            0.893939   \n",
       "6             0.820896            0.835821            0.818182   \n",
       "7             0.850746            0.880597            0.909091   \n",
       "8             0.820896            0.791045            0.787879   \n",
       "9             0.835821            0.880597            0.863636   \n",
       "10            0.805970            0.761194            0.787879   \n",
       "11            0.805970            0.850746            0.803030   \n",
       "12            0.761194            0.776119            0.772727   \n",
       "13            0.805970            0.835821            0.848485   \n",
       "14            0.746269            0.761194            0.803030   \n",
       "15            0.865672            0.805970            0.848485   \n",
       "16            0.776119            0.776119            0.772727   \n",
       "17            0.791045            0.791045            0.803030   \n",
       "18            0.791045            0.686567            0.742424   \n",
       "\n",
       "    split4_train_score  mean_train_score  std_train_score  \n",
       "0             0.878788          0.858345         0.032712  \n",
       "1             0.924242          0.912619         0.022241  \n",
       "2             0.863636          0.867436         0.020279  \n",
       "3             0.909091          0.900678         0.025961  \n",
       "4             0.833333          0.816327         0.023633  \n",
       "5             0.893939          0.876572         0.017051  \n",
       "6             0.818182          0.798010         0.050944  \n",
       "7             0.818182          0.855360         0.035524  \n",
       "8             0.787879          0.776934         0.041870  \n",
       "9             0.833333          0.834193         0.042175  \n",
       "10            0.787879          0.767978         0.038272  \n",
       "11            0.818182          0.810131         0.025224  \n",
       "12            0.787879          0.762008         0.026354  \n",
       "13            0.863636          0.831389         0.023673  \n",
       "14            0.833333          0.771190         0.042628  \n",
       "15            0.863636          0.840389         0.024179  \n",
       "16            0.787879          0.768024         0.021015  \n",
       "17            0.878788          0.813388         0.033137  \n",
       "18            0.787879          0.756128         0.038805  \n",
       "\n",
       "[19 rows x 21 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set the parameter grid.\n",
    "param_grid = {\n",
    "    'n_neighbors': range(2, 21)\n",
    "}\n",
    "\n",
    "# Perform grid search with 5-fold cross-validation to find the best value for k (number of neighbors)\n",
    "mine_detector_grid = GridSearchCV(estimator = knn_spec,\n",
    "                                  param_grid = param_grid,\n",
    "                                  cv=5,\n",
    "                                  return_train_score=True,\n",
    "                                  scoring='recall')\n",
    "\n",
    "mine_detector_grid.fit(X_train, y_train)\n",
    "\n",
    "CV_results = pd.DataFrame(mine_detector_grid.fit(X_train,y_train).cv_results_)\n",
    "CV_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ec580-dd11-48b2-8d0d-722b127757b3",
   "metadata": {},
   "source": [
    "With the result in hand, we visualize the model's performance with different K in a line chart, to help us find the best K. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5bea0baf-7c23-42a1-80d0-cf181e09cc18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-1751923dd8584d82beadbb8d923f8992\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-1751923dd8584d82beadbb8d923f8992\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-1751923dd8584d82beadbb8d923f8992\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0364f7fbdb1742c3fdcfcd3bd8cb6dad\"}, \"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"x\": {\"field\": \"param_n_neighbors\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"mean_test_score\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-0364f7fbdb1742c3fdcfcd3bd8cb6dad\": [{\"mean_fit_time\": 0.0029969215393066406, \"std_fit_time\": 0.00039564167792874733, \"mean_score_time\": 0.005377769470214844, \"std_score_time\": 0.00024330734563834862, \"param_n_neighbors\": 2, \"params\": {\"n_neighbors\": 2}, \"split0_test_score\": 0.6470588235294118, \"split1_test_score\": 0.6875, \"split2_test_score\": 0.875, \"split3_test_score\": 0.8235294117647058, \"split4_test_score\": 0.7647058823529411, \"mean_test_score\": 0.7595588235294117, \"std_test_score\": 0.08401680504168058, \"rank_test_score\": 11, \"split0_train_score\": 0.8484848484848485, \"split1_train_score\": 0.9104477611940298, \"split2_train_score\": 0.835820895522388, \"split3_train_score\": 0.8181818181818182, \"split4_train_score\": 0.8787878787878788, \"mean_train_score\": 0.8583446404341928, \"std_train_score\": 0.03271161280252631}, {\"mean_fit_time\": 0.0031331062316894533, \"std_fit_time\": 0.00039669299195877904, \"mean_score_time\": 0.00588693618774414, \"std_score_time\": 0.000876381432399008, \"param_n_neighbors\": 3, \"params\": {\"n_neighbors\": 3}, \"split0_test_score\": 0.7647058823529411, \"split1_test_score\": 0.8125, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.9411764705882353, \"split4_test_score\": 0.9411764705882353, \"mean_test_score\": 0.8794117647058824, \"std_test_score\": 0.07568173434518273, \"rank_test_score\": 1, \"split0_train_score\": 0.8787878787878788, \"split1_train_score\": 0.9402985074626866, \"split2_train_score\": 0.8955223880597015, \"split3_train_score\": 0.9242424242424242, \"split4_train_score\": 0.9242424242424242, \"mean_train_score\": 0.912618724559023, \"std_train_score\": 0.02224051266289844}, {\"mean_fit_time\": 0.008445978164672852, \"std_fit_time\": 0.011055391991923279, \"mean_score_time\": 0.005346155166625977, \"std_score_time\": 0.00048049374943208824, \"param_n_neighbors\": 4, \"params\": {\"n_neighbors\": 4}, \"split0_test_score\": 0.5882352941176471, \"split1_test_score\": 0.625, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.8235294117647058, \"split4_test_score\": 0.8823529411764706, \"mean_test_score\": 0.7713235294117647, \"std_test_score\": 0.13971362207663082, \"rank_test_score\": 8, \"split0_train_score\": 0.8333333333333334, \"split1_train_score\": 0.8656716417910447, \"split2_train_score\": 0.8805970149253731, \"split3_train_score\": 0.8939393939393939, \"split4_train_score\": 0.8636363636363636, \"mean_train_score\": 0.8674355495251017, \"std_train_score\": 0.020278975680843}, {\"mean_fit_time\": 0.0034447193145751955, \"std_fit_time\": 0.0004653369613739165, \"mean_score_time\": 0.006303977966308594, \"std_score_time\": 0.0007567161028487518, \"param_n_neighbors\": 5, \"params\": {\"n_neighbors\": 5}, \"split0_test_score\": 0.7647058823529411, \"split1_test_score\": 0.75, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.8823529411764706, \"split4_test_score\": 0.8823529411764706, \"mean_test_score\": 0.8433823529411765, \"std_test_score\": 0.07321993696767413, \"rank_test_score\": 2, \"split0_train_score\": 0.8787878787878788, \"split1_train_score\": 0.8656716417910447, \"split2_train_score\": 0.9104477611940298, \"split3_train_score\": 0.9393939393939394, \"split4_train_score\": 0.9090909090909091, \"mean_train_score\": 0.9006784260515603, \"std_train_score\": 0.02596063079797143}, {\"mean_fit_time\": 0.0032855987548828123, \"std_fit_time\": 0.0004231653580584792, \"mean_score_time\": 0.006062984466552734, \"std_score_time\": 0.0007035655435228562, \"param_n_neighbors\": 6, \"params\": {\"n_neighbors\": 6}, \"split0_test_score\": 0.5882352941176471, \"split1_test_score\": 0.6875, \"split2_test_score\": 0.75, \"split3_test_score\": 0.8823529411764706, \"split4_test_score\": 0.8235294117647058, \"mean_test_score\": 0.7463235294117647, \"std_test_score\": 0.10288864205712824, \"rank_test_score\": 13, \"split0_train_score\": 0.7878787878787878, \"split1_train_score\": 0.8208955223880597, \"split2_train_score\": 0.7910447761194029, \"split3_train_score\": 0.8484848484848485, \"split4_train_score\": 0.8333333333333334, \"mean_train_score\": 0.8163274536408865, \"std_train_score\": 0.02363347458856732}, {\"mean_fit_time\": 0.002770662307739258, \"std_fit_time\": 3.338405019695103e-05, \"mean_score_time\": 0.005215358734130859, \"std_score_time\": 8.998908952031601e-05, \"param_n_neighbors\": 7, \"params\": {\"n_neighbors\": 7}, \"split0_test_score\": 0.7058823529411765, \"split1_test_score\": 0.75, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.8823529411764706, \"split4_test_score\": 0.8235294117647058, \"mean_test_score\": 0.8198529411764707, \"std_test_score\": 0.08441483905038918, \"rank_test_score\": 5, \"split0_train_score\": 0.8636363636363636, \"split1_train_score\": 0.8507462686567164, \"split2_train_score\": 0.8805970149253731, \"split3_train_score\": 0.8939393939393939, \"split4_train_score\": 0.8939393939393939, \"mean_train_score\": 0.8765716870194483, \"std_train_score\": 0.017051408016346196}, {\"mean_fit_time\": 0.002767515182495117, \"std_fit_time\": 3.437840488640207e-05, \"mean_score_time\": 0.005265426635742187, \"std_score_time\": 5.198627320038698e-05, \"param_n_neighbors\": 8, \"params\": {\"n_neighbors\": 8}, \"split0_test_score\": 0.47058823529411764, \"split1_test_score\": 0.75, \"split2_test_score\": 0.875, \"split3_test_score\": 0.7647058823529411, \"split4_test_score\": 0.6470588235294118, \"mean_test_score\": 0.7014705882352941, \"std_test_score\": 0.13618631650341442, \"rank_test_score\": 18, \"split0_train_score\": 0.696969696969697, \"split1_train_score\": 0.8208955223880597, \"split2_train_score\": 0.835820895522388, \"split3_train_score\": 0.8181818181818182, \"split4_train_score\": 0.8181818181818182, \"mean_train_score\": 0.7980099502487563, \"std_train_score\": 0.05094380882726196}, {\"mean_fit_time\": 0.002849912643432617, \"std_fit_time\": 0.00014549047956703538, \"mean_score_time\": 0.005387592315673828, \"std_score_time\": 0.0002468496853032489, \"param_n_neighbors\": 9, \"params\": {\"n_neighbors\": 9}, \"split0_test_score\": 0.5882352941176471, \"split1_test_score\": 0.8125, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.8823529411764706, \"split4_test_score\": 0.8823529411764706, \"mean_test_score\": 0.8205882352941177, \"std_test_score\": 0.12276109101473488, \"rank_test_score\": 4, \"split0_train_score\": 0.8181818181818182, \"split1_train_score\": 0.8507462686567164, \"split2_train_score\": 0.8805970149253731, \"split3_train_score\": 0.9090909090909091, \"split4_train_score\": 0.8181818181818182, \"mean_train_score\": 0.855359565807327, \"std_train_score\": 0.035523621540197683}, {\"mean_fit_time\": 0.0027644157409667967, \"std_fit_time\": 3.458118279604028e-05, \"mean_score_time\": 0.005320405960083008, \"std_score_time\": 0.0002509149386620117, \"param_n_neighbors\": 10, \"params\": {\"n_neighbors\": 10}, \"split0_test_score\": 0.5294117647058824, \"split1_test_score\": 0.8125, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.8823529411764706, \"split4_test_score\": 0.8235294117647058, \"mean_test_score\": 0.7970588235294118, \"std_test_score\": 0.1411190140433509, \"rank_test_score\": 6, \"split0_train_score\": 0.696969696969697, \"split1_train_score\": 0.8208955223880597, \"split2_train_score\": 0.7910447761194029, \"split3_train_score\": 0.7878787878787878, \"split4_train_score\": 0.7878787878787878, \"mean_train_score\": 0.7769335142469471, \"std_train_score\": 0.04187026623926209}, {\"mean_fit_time\": 0.0029076576232910157, \"std_fit_time\": 0.00029894832462375425, \"mean_score_time\": 0.005162477493286133, \"std_score_time\": 7.166689580683099e-05, \"param_n_neighbors\": 11, \"params\": {\"n_neighbors\": 11}, \"split0_test_score\": 0.6470588235294118, \"split1_test_score\": 0.8125, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.8823529411764706, \"split4_test_score\": 0.8823529411764706, \"mean_test_score\": 0.8323529411764706, \"std_test_score\": 0.10078090423011417, \"rank_test_score\": 3, \"split0_train_score\": 0.7575757575757576, \"split1_train_score\": 0.835820895522388, \"split2_train_score\": 0.8805970149253731, \"split3_train_score\": 0.8636363636363636, \"split4_train_score\": 0.8333333333333334, \"mean_train_score\": 0.8341926729986431, \"std_train_score\": 0.042175431640203674}, {\"mean_fit_time\": 0.0029877185821533202, \"std_fit_time\": 0.0004407701628897769, \"mean_score_time\": 0.005640840530395508, \"std_score_time\": 0.0006262590807175222, \"param_n_neighbors\": 12, \"params\": {\"n_neighbors\": 12}, \"split0_test_score\": 0.5294117647058824, \"split1_test_score\": 0.6875, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.7647058823529411, \"split4_test_score\": 0.7647058823529411, \"mean_test_score\": 0.7367647058823529, \"std_test_score\": 0.1321198928623748, \"rank_test_score\": 14, \"split0_train_score\": 0.696969696969697, \"split1_train_score\": 0.8059701492537313, \"split2_train_score\": 0.7611940298507462, \"split3_train_score\": 0.7878787878787878, \"split4_train_score\": 0.7878787878787878, \"mean_train_score\": 0.7679782903663501, \"std_train_score\": 0.03827188908616494}, {\"mean_fit_time\": 0.0028921127319335937, \"std_fit_time\": 0.00014782633304272628, \"mean_score_time\": 0.005625343322753907, \"std_score_time\": 0.00041346023434354786, \"param_n_neighbors\": 13, \"params\": {\"n_neighbors\": 13}, \"split0_test_score\": 0.5882352941176471, \"split1_test_score\": 0.6875, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.7647058823529411, \"split4_test_score\": 0.8235294117647058, \"mean_test_score\": 0.7602941176470589, \"std_test_score\": 0.11859453035346017, \"rank_test_score\": 9, \"split0_train_score\": 0.7727272727272727, \"split1_train_score\": 0.8059701492537313, \"split2_train_score\": 0.8507462686567164, \"split3_train_score\": 0.803030303030303, \"split4_train_score\": 0.8181818181818182, \"mean_train_score\": 0.8101311623699683, \"std_train_score\": 0.0252237471903081}, {\"mean_fit_time\": 0.0036588668823242187, \"std_fit_time\": 0.0016222211179307798, \"mean_score_time\": 0.005399131774902343, \"std_score_time\": 0.0002586039009934219, \"param_n_neighbors\": 14, \"params\": {\"n_neighbors\": 14}, \"split0_test_score\": 0.47058823529411764, \"split1_test_score\": 0.5625, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.7647058823529411, \"split4_test_score\": 0.8235294117647058, \"mean_test_score\": 0.7117647058823529, \"std_test_score\": 0.17128723422659534, \"rank_test_score\": 17, \"split0_train_score\": 0.7121212121212122, \"split1_train_score\": 0.7611940298507462, \"split2_train_score\": 0.7761194029850746, \"split3_train_score\": 0.7727272727272727, \"split4_train_score\": 0.7878787878787878, \"mean_train_score\": 0.7620081411126188, \"std_train_score\": 0.02635407490178909}, {\"mean_fit_time\": 0.003241109848022461, \"std_fit_time\": 0.0005631661310076777, \"mean_score_time\": 0.00786137580871582, \"std_score_time\": 0.004795848976212923, \"param_n_neighbors\": 15, \"params\": {\"n_neighbors\": 15}, \"split0_test_score\": 0.5882352941176471, \"split1_test_score\": 0.625, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.8235294117647058, \"split4_test_score\": 0.8235294117647058, \"mean_test_score\": 0.7595588235294117, \"std_test_score\": 0.13214035214256037, \"rank_test_score\": 11, \"split0_train_score\": 0.803030303030303, \"split1_train_score\": 0.8059701492537313, \"split2_train_score\": 0.835820895522388, \"split3_train_score\": 0.8484848484848485, \"split4_train_score\": 0.8636363636363636, \"mean_train_score\": 0.8313885119855268, \"std_train_score\": 0.023673343070734744}, {\"mean_fit_time\": 0.002835369110107422, \"std_fit_time\": 0.00011077950397908983, \"mean_score_time\": 0.005700159072875977, \"std_score_time\": 0.0003817952197925019, \"param_n_neighbors\": 16, \"params\": {\"n_neighbors\": 16}, \"split0_test_score\": 0.5294117647058824, \"split1_test_score\": 0.625, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.7647058823529411, \"split4_test_score\": 0.8235294117647058, \"mean_test_score\": 0.7360294117647058, \"std_test_score\": 0.1442826186636592, \"rank_test_score\": 15, \"split0_train_score\": 0.7121212121212122, \"split1_train_score\": 0.746268656716418, \"split2_train_score\": 0.7611940298507462, \"split3_train_score\": 0.803030303030303, \"split4_train_score\": 0.8333333333333334, \"mean_train_score\": 0.7711895070104025, \"std_train_score\": 0.04262795619162677}, {\"mean_fit_time\": 0.0027977943420410155, \"std_fit_time\": 0.0001086416095452048, \"mean_score_time\": 0.005287551879882812, \"std_score_time\": 0.00013699329897879812, \"param_n_neighbors\": 17, \"params\": {\"n_neighbors\": 17}, \"split0_test_score\": 0.6470588235294118, \"split1_test_score\": 0.625, \"split2_test_score\": 1.0, \"split3_test_score\": 0.8823529411764706, \"split4_test_score\": 0.8235294117647058, \"mean_test_score\": 0.7955882352941176, \"std_test_score\": 0.14230553415768168, \"rank_test_score\": 7, \"split0_train_score\": 0.8181818181818182, \"split1_train_score\": 0.8656716417910447, \"split2_train_score\": 0.8059701492537313, \"split3_train_score\": 0.8484848484848485, \"split4_train_score\": 0.8636363636363636, \"mean_train_score\": 0.8403889642695613, \"std_train_score\": 0.024178547787898866}, {\"mean_fit_time\": 0.004036045074462891, \"std_fit_time\": 0.0015689021482147558, \"mean_score_time\": 0.006264781951904297, \"std_score_time\": 0.0009374701551960372, \"param_n_neighbors\": 18, \"params\": {\"n_neighbors\": 18}, \"split0_test_score\": 0.47058823529411764, \"split1_test_score\": 0.5625, \"split2_test_score\": 1.0, \"split3_test_score\": 0.6470588235294118, \"split4_test_score\": 0.8235294117647058, \"mean_test_score\": 0.7007352941176471, \"std_test_score\": 0.18952339604138277, \"rank_test_score\": 19, \"split0_train_score\": 0.7272727272727273, \"split1_train_score\": 0.7761194029850746, \"split2_train_score\": 0.7761194029850746, \"split3_train_score\": 0.7727272727272727, \"split4_train_score\": 0.7878787878787878, \"mean_train_score\": 0.7680235187697875, \"std_train_score\": 0.021014617306888684}, {\"mean_fit_time\": 0.002810811996459961, \"std_fit_time\": 0.00012594321018145668, \"mean_score_time\": 0.005463600158691406, \"std_score_time\": 0.00034285768825605606, \"param_n_neighbors\": 19, \"params\": {\"n_neighbors\": 19}, \"split0_test_score\": 0.47058823529411764, \"split1_test_score\": 0.625, \"split2_test_score\": 1.0, \"split3_test_score\": 0.8235294117647058, \"split4_test_score\": 0.8823529411764706, \"mean_test_score\": 0.7602941176470588, \"std_test_score\": 0.18899204501667466, \"rank_test_score\": 10, \"split0_train_score\": 0.803030303030303, \"split1_train_score\": 0.7910447761194029, \"split2_train_score\": 0.7910447761194029, \"split3_train_score\": 0.803030303030303, \"split4_train_score\": 0.8787878787878788, \"mean_train_score\": 0.8133876074174582, \"std_train_score\": 0.03313652735121089}, {\"mean_fit_time\": 0.003968477249145508, \"std_fit_time\": 0.0010928865083861643, \"mean_score_time\": 0.006222057342529297, \"std_score_time\": 0.0008973081226604499, \"param_n_neighbors\": 20, \"params\": {\"n_neighbors\": 20}, \"split0_test_score\": 0.4117647058823529, \"split1_test_score\": 0.625, \"split2_test_score\": 0.9375, \"split3_test_score\": 0.7647058823529411, \"split4_test_score\": 0.8823529411764706, \"mean_test_score\": 0.7242647058823529, \"std_test_score\": 0.1895291013982196, \"rank_test_score\": 16, \"split0_train_score\": 0.7727272727272727, \"split1_train_score\": 0.7910447761194029, \"split2_train_score\": 0.6865671641791045, \"split3_train_score\": 0.7424242424242424, \"split4_train_score\": 0.7878787878787878, \"mean_train_score\": 0.7561284486657621, \"std_train_score\": 0.03880549572254136}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_plot = alt.Chart(CV_results).mark_line(point=True).encode(\n",
    "    x = alt.X(\"param_n_neighbors\"),\n",
    "    y = alt.Y(\"mean_test_score\")\n",
    ")\n",
    "recall_plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5194d59-8d76-424e-b489-69615dc220a5",
   "metadata": {},
   "source": [
    "It seems we have the highest recall when K = 3. We will choose this to train our model! Other K values give us a recall below 85%, which is not acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc102138-a24f-49e7-b8d2-d0cd9d19cb6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the random seed.\n",
    "np.random.seed(2023)\n",
    "\n",
    "mine_detector_spec = KNeighborsClassifier( n_neighbors = 3)\n",
    "mine_detector_fit = mine_detector_spec.fit (X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432c7791-3836-48d2-a914-d56dd747b09e",
   "metadata": {},
   "source": [
    "The model is trained. Now we are going to use the test data set to evaluate the model's performance. We will compare the prediction and the true value side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae9593a8-df75-4590-bd73-80d71b751a8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Label</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     True Label  Prediction\n",
       "145           1           0\n",
       "134           1           1\n",
       "177           1           0\n",
       "31            0           0\n",
       "15            0           0\n",
       "147           1           1\n",
       "14            0           0\n",
       "106           1           1\n",
       "207           1           0\n",
       "16            0           0\n",
       "205           1           1\n",
       "65            0           0\n",
       "56            0           0\n",
       "114           1           1\n",
       "203           1           1\n",
       "198           1           1\n",
       "174           1           1\n",
       "77            0           0\n",
       "18            0           0\n",
       "187           1           1\n",
       "120           1           1\n",
       "186           1           1\n",
       "170           1           1\n",
       "46            0           1\n",
       "185           1           1\n",
       "164           1           0\n",
       "115           1           1\n",
       "39            0           0\n",
       "34            0           1\n",
       "94            0           1\n",
       "40            0           0\n",
       "162           1           0\n",
       "193           1           1\n",
       "51            0           0\n",
       "32            0           1\n",
       "140           1           1\n",
       "90            0           0\n",
       "42            0           0\n",
       "84            0           0\n",
       "66            0           0\n",
       "116           1           1\n",
       "124           1           1\n",
       "64            0           0\n",
       "9             0           0\n",
       "85            0           0\n",
       "194           1           1\n",
       "62            0           0\n",
       "156           1           1\n",
       "110           1           1\n",
       "129           1           1\n",
       "166           1           0\n",
       "28            0           1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mine_detector_reality_check = pd.DataFrame({\"True Label\": y_test,\n",
    "                                           \"Prediction\": mine_detector_fit .predict(X_test)})\n",
    "Mine_detector_reality_check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb6fbba-9087-406f-95aa-2e03a43d80f1",
   "metadata": {},
   "source": [
    "In many instances the model seems to give an incorrect labeling. We will take a closer look by constructing a confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18e2ecd5-6c13-4587-bee3-3fcd1f1e9cf4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction   0   1\n",
       "True Label        \n",
       "0           19   5\n",
       "1            6  22"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_conf_mat = pd.crosstab(Mine_detector_reality_check[\"True Label\"],\n",
    "                             Mine_detector_reality_check[\"Prediction\"])\n",
    "\n",
    "mnist_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feafb830-23a1-4786-b2ae-ee74adb7f874",
   "metadata": {},
   "source": [
    "Recall that 0 is Rock and 1 is Mine, we move on to report the recall and accuracy of our model.\n",
    "\n",
    "$\\mathrm{precision} = \\frac{\\mathrm{number \\; of  \\; correct \\; positive \\; predictions}}{\\mathrm{total \\;  number \\;  of \\; positive  \\; predictions}}$\n",
    "\n",
    "$\\mathrm{recall} = \\frac{\\mathrm{number \\; of  \\; correct  \\; positive \\; predictions}}{\\mathrm{total \\;  number \\;  of  \\; positive \\; test \\; set \\; observations}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4bbada2-127c-432c-9c46-66852c6ecdeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8148148148148148"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mine_precision= 22/ (5+22)\n",
    "Mine_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfdf1c90-2be0-4ec9-9dda-bc1b6410fa26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7857142857142857"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mine_recall = 22/ (6+22)\n",
    "Mine_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac191594-8ded-4a3b-a62c-9897b840f614",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "With the analysis, we have successfully trained a Knn-model that can distinguish water mine from rocks based on the signal of a sonar system. We have determined that for the sake of public safety, recall should be favored when training the model. With a Gridsearch, we conclude that the model produces the highest recall by choose K = 3. This classifier model rendered a 78.6% recall, which is good. However, there is still a lot of room for it to improve.\n",
    "\n",
    "## For Winnie and Farbod\n",
    "\n",
    "- discuss whether this is what you expected to find?\n",
    "    We expect to use our classifier to predict whether the object underwater is an explosive mine or a rock.\n",
    "- discuss what impact could such findings have?\n",
    "    This model allows us to automate the water mine detection. With such a model, underwater robots can locate and flag mines automatically. They can search through a large area of water thoroughly. It is hard for humans because it is expensive to train and hire human analysts. This can save the lives of civilians, especially the fishermen. On the other hand, it is also important for national defense because it can protect the expensive battleships.\n",
    "    \n",
    "- discuss what future questions could this lead to?\n",
    "    This analysis could lead to future questions such as whether there is a way to train the model with fewer parameters and, if so, how to find them, whether the model can detect mines of other shapes, and whether we can develop a model that can label the type of the mine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c73929-63fe-433e-afcb-c2e30427503a",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Gorman, R. Paul and Terrence J. Sejnowski. “Analysis of hidden units in a layered network trained to classify sonar targets.” Neural Networks 1 (1988): 75-89."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2572abf1-d481-402f-be0f-05f83df72804",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
